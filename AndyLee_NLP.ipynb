{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "AndyLee-NLP.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danieljai/CIND820-AndyLee/blob/main/AndyLee_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsvQObEApoiu"
      },
      "source": [
        "### Outstanding tasks\n",
        "- remove retweets RT @\n",
        "- convert html entities to their own\n",
        "- remove hyperlinks\n",
        "- remove \\n\n",
        "- remove tweet ID mentions\n",
        "- remove non-English tweets\n",
        "- write code to allow easier future presentation\n",
        "- study NLP lectures to cover gaps in knwoledge\n",
        "- GCP Google Cloud - COLAB, should be able to use it under Ryerson\n",
        "- keep notebook diary \n",
        "\n",
        "11/11\n",
        "- add readme file explaining rehydration process\n",
        "- also explain anything that was done outside of python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uncPLiQYnn0"
      },
      "source": [
        "# Preload setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VJ3TVjfpoiz"
      },
      "source": [
        "%config IPCompleter.greedy=True\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_colwidth', 200)\n",
        "pd.options.display.max_colwidth = 500\n",
        "pd.options.display.max_rows = 100"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbYv2dHQYl-W"
      },
      "source": [
        "# Import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWSJpsyKqHjH",
        "outputId": "7af6f5dc-bba8-4953-bb33-b5fee7d058bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "IhVcP_VWpoiv"
      },
      "source": [
        "\n",
        "\n",
        "#df = pd.read_csv('Book1-fastsave.csv')\n",
        "df = pd.read_csv(\"/content/drive/My Drive/__CIND 820 - Data Analytics Project/3-data/Book1-fastsave.csv\")\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlWWaQWaRrcG"
      },
      "source": [
        "- Setting display options\n",
        "- previewing the text attribute"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEl8PsIfYPlI"
      },
      "source": [
        "# Data Cleaning and Manipulation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZfDm-YdvsBC"
      },
      "source": [
        "## Readjust attribute datatype\n",
        "\n",
        "For `retweet_id`, `in_reply_to_status_id`, `in_reply_to_user_id`\n",
        "- Convert `null` values to 0\n",
        "- Convert attribute as int64"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNtxXnmyuroY"
      },
      "source": [
        "df.retweet_id = df[df['retweet_id'].notnull()].retweet_id.astype('int64') "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wq7nVqm-Ybq5"
      },
      "source": [
        "df.retweet_id = df.retweet_id.fillna(0).astype('int64')\n",
        "df.in_reply_to_status_id = df.in_reply_to_status_id.fillna(0).astype('int64')\n",
        "df.in_reply_to_user_id = df.in_reply_to_user_id.fillna(0).astype('int64')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1vhtGcnzqtp"
      },
      "source": [
        "## Misc. cleaning up to reduce noise when conducting sentimental analysis\n",
        "1. remove \\n\n",
        "2. remove URL\n",
        "3. remove user referrals\n",
        "4. remove hashtags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGLSjXA00aBs"
      },
      "source": [
        "df['modified_text'] = df.text.str.replace(r'\\n', '')\n",
        "df['modified_text'] = df.modified_text.str.replace(r'(http|ftp|https)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?', '')\n",
        "df['modified_text'] = df.modified_text.str.replace(r'\\B@\\w+', '')\n",
        "df['modified_text'] = df.modified_text.str.replace(r'\\B#\\w+', '')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XU0njxYunzu"
      },
      "source": [
        "## Splitting Dataframes (originals and retweets)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d0LEsJceIY5"
      },
      "source": [
        "The collection includes both original tweets and retweets. Since retweets mirrors the original tweet by someone else other than the author, we don't need to run sentimental analysis on the retweet as it would have been run on the original tweet, therefore we can split original tweets and retweets into two dataframes to avoid wasting resources.\n",
        "\n",
        "\n",
        "- Original tweets: `dfOriginals`\n",
        "- Retweets: `dfRetweets` cons\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPydisljWkFM"
      },
      "source": [
        "dfOriginals = df[df.retweet_id == 0]\n",
        "dfRetweets = df[df.retweet_id != 0]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RbFQ3a7OgDj"
      },
      "source": [
        "## Preview data after cleaning and manipulation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "791wvRVcqsA0"
      },
      "source": [
        "Original Tweet dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5nEYW5qOVAg"
      },
      "source": [
        "dfOriginals.head(5)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aI-iPEBiqupJ"
      },
      "source": [
        "Retweet dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0R9fv6oN57r"
      },
      "source": [
        "dfRetweets.head(5)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jfq66BaYpojK"
      },
      "source": [
        "## Guessing language"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPwDbh-HmBv8",
        "outputId": "38df2e77-c115-4dc3-b9e8-e88910fdf202",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#https://pypi.org/project/langdetect/\n",
        "!pip install langdetect\n",
        "from langdetect import detect\n",
        "from langdetect import DetectorFactory\n",
        "DetectorFactory.seed = 0\n",
        "\n",
        "# import multiprocessing as mp\n",
        "# p=mp.Pool(4)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting langdetect\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/a3/8407c1e62d5980188b4acc45ef3d94b933d14a2ebc9ef3505f22cf772570/langdetect-1.0.8.tar.gz (981kB)\n",
            "\u001b[K     |████████████████████████████████| 983kB 5.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from langdetect) (1.15.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.8-cp36-none-any.whl size=993195 sha256=93f518a9e73007c3fb8b5f9e1fc1a8f70691bbb7a6e1562c0749a140a5c71052\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/b3/aa/6d99de9f3841d7d3d40a60ea06e6d669e8e5012e6c8b947a57\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90SL1Mb_sGoL"
      },
      "source": [
        "# p.map(detect,dfOriginals.sample(500).text)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVylF_Uf2AWT"
      },
      "source": [
        "dfOriginals = dfOriginals[~(dfOriginals.modified_text == \"\")]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAl2FWRd7leq",
        "outputId": "c50e3c93-3ab1-450c-ca41-a63319e43419",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "dfOriginals[(dfOriginals.modified_text == \"\")]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>coordinates</th>\n",
              "      <th>created_at</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>media</th>\n",
              "      <th>urls</th>\n",
              "      <th>favorite_count</th>\n",
              "      <th>id</th>\n",
              "      <th>in_reply_to_screen_name</th>\n",
              "      <th>in_reply_to_status_id</th>\n",
              "      <th>in_reply_to_user_id</th>\n",
              "      <th>lang</th>\n",
              "      <th>place</th>\n",
              "      <th>possibly_sensitive</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>retweet_id</th>\n",
              "      <th>retweet_screen_name</th>\n",
              "      <th>source</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_url</th>\n",
              "      <th>user_created_at</th>\n",
              "      <th>user_screen_name</th>\n",
              "      <th>user_default_profile_image</th>\n",
              "      <th>user_description</th>\n",
              "      <th>user_favourites_count</th>\n",
              "      <th>user_followers_count</th>\n",
              "      <th>user_friends_count</th>\n",
              "      <th>user_listed_count</th>\n",
              "      <th>user_location</th>\n",
              "      <th>user_name</th>\n",
              "      <th>user_screen_name.1</th>\n",
              "      <th>user_statuses_count</th>\n",
              "      <th>user_time_zone</th>\n",
              "      <th>user_urls</th>\n",
              "      <th>user_verified</th>\n",
              "      <th>modified_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [coordinates, created_at, hashtags, media, urls, favorite_count, id, in_reply_to_screen_name, in_reply_to_status_id, in_reply_to_user_id, lang, place, possibly_sensitive, retweet_count, retweet_id, retweet_screen_name, source, text, tweet_url, user_created_at, user_screen_name, user_default_profile_image, user_description, user_favourites_count, user_followers_count, user_friends_count, user_listed_count, user_location, user_name, user_screen_name.1, user_statuses_count, user_time_zone, user_urls, user_verified, modified_text]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPdqdngRnI8B"
      },
      "source": [
        "add markdown giving explanation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJWNxzqbQhIz"
      },
      "source": [
        "def is_en(txt):\n",
        "    try:\n",
        "        return detect(txt)=='en'\n",
        "    except:\n",
        "        return False"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5X_Wv9YRBKh",
        "outputId": "2d322981-ef24-4823-8cde-88847841c2d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dfOriginals.sample(5).text.apply(is_en)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "610219    True\n",
              "185159    True\n",
              "745618    True\n",
              "40189     True\n",
              "227659    True\n",
              "Name: text, dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCxbwQfSmht4"
      },
      "source": [
        "#https://stackoverflow.com/questions/60930935/exclude-non-english-rows-in-pandas\n",
        "\n",
        "dfOriginals['guessed_language'] = dfOriginals.modified_text.apply(is_en)\n",
        "\n",
        "# split to cores\n",
        "# dfOriginals['guessed_language'] = p.map(is_en,dfOriginals.modified_text)\n",
        "#dfOriginals.sample(1000).text.apply(detect)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsfksiehng6H"
      },
      "source": [
        "- give extra information the analysis process\n",
        "- what action did to the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPoRWDGSXx99"
      },
      "source": [
        "sum(dfOriginals.guessed_language)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsaEzcwYYa-t"
      },
      "source": [
        "len(dfOriginals)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atZ26M3rYTfg"
      },
      "source": [
        "# Being Sentiment Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezcFLOzHLRE_"
      },
      "source": [
        "Import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxgmxMWypoi2"
      },
      "source": [
        "import nltk\n",
        "from nltk.sentiment.util import *\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from nltk import tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('vader_lexicon')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-LaUqLn6Huk"
      },
      "source": [
        "sid = SentimentIntensityAnalyzer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JThgKwNppoi_"
      },
      "source": [
        "# for sentence in sentences:\n",
        "#      print(sentence)\n",
        "#      ss = sid.polarity_scores(sentence)\n",
        "#      for k in sorted(ss):\n",
        "#          print('{0}: {1}, '.format(k, ss[k]), end='')\n",
        "#      print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhrR1DkvcgNO"
      },
      "source": [
        "## Calculating Setimental Score\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zjw8l4kapojF"
      },
      "source": [
        "dfOriginals['sentimentscore'] = dfOriginals.text.apply(sid.polarity_scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKHk7KzTXSNZ"
      },
      "source": [
        "Quick preview of the sentiment score and its text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juosFirzpojI"
      },
      "source": [
        "dfOriginals.sample(30)[['modified_text','sentimentscore']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9GcU1qtEKha"
      },
      "source": [
        "# dfOriginals.sentimentscore.head(5)\n",
        "dfOriginalSScore = pd.json_normalize(dfOriginals.sentimentscore)\n",
        "dfOriginalSScore['original_index'] = dfOriginals.index\n",
        "dfOriginalSScore = dfOriginalSScore.set_index('original_index')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwXfu-6mHoTA"
      },
      "source": [
        "# dfOriginals.join(dfOriginalSScore)\n",
        "dfOriginalSScore.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrYE5MAfoODY"
      },
      "source": [
        "- need some explanation on the \"compound\" attribute\n",
        "- have an answer what the compound score stands for."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoK5ZqBlU9Wa"
      },
      "source": [
        "# pd.merge(dfOriginals, dfOriginalSScore, left_index=True, right_index='original_index')\n",
        "dfOriginals.merge(dfOriginalSScore, left_index=True, right_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijaX3C_HonE7"
      },
      "source": [
        "- impact factor of a tweet "
      ]
    }
  ]
}